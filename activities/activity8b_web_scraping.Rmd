---
title: "Web Scraping with `rvest`"
subtitle: "Math 241, Week 5"
output: pdf_document
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

```{r}
#Load web scraping library
library(rvest)
```

# Grab Tables from the Web

Let's grab the **Portland area sports teams** table on Portland's [Wikipedia page](https://en.wikipedia.org/wiki/Portland,_Oregon).

```{r}
#Store url
url <- "https://en.wikipedia.org/wiki/Portland,_Oregon"

## Scrape html and store table

#Grab all the tables and then navigate to the one you wanted.
tables <- url %>%
  read_html() %>%
  html_nodes(css = "table")

#Grab the specific table
champ_table <- html_table(tables[[8]], fill = TRUE)
champ_table

```

## Population data over time

Using the same approach, grab the table of Portland's population over time (table 4), and create a simple visualization of the total population count over time.

```{r}
population_table <- html_table(tables[[4]], fill = TRUE)
population_table
population_table <- population_table %>% mutate(Pop. = recode(Pop., "2,874" = "2874", "8,293" = "8293", "17,577" = "17577", "46,385" = "46385", "90,426" = "90426", "207,214" = "207214", "258,288" = "258288", "301,815" = "301815", "305,394" = "305394", "373,628" = "373628", "372,676" = "372676", "382,619" = "382619", "366,383" = "366383", "437,319" = "437319", "529,121" = "529121", "583,776" = "583776", "652,503" = "652503", "635,067" = "635067"))

ggplot(population_table, aes(x = Census, y = Pop.)) +
  geom_point()
```

# Another Example

* Although we saw that we can use `datapasta` to grab these data, let's scrape the [NYTimes.com's College Access Index](https://www.nytimes.com/interactive/2017/05/25/sunday-review/opinion-pell-table.html) table.

```{r}
# Store url
url <- "https://www.nytimes.com/interactive/2017/05/25/sunday-review/opinion-pell-table.html"

## Scrape html and store table

# Grab the table
tables <- url %>%
  read_html() %>%
  html_nodes(css = "table")

#Grab the specific table
college_access_table <- html_table(tables[[1]], fill = TRUE)

#Option 2: Use the specific css
college_access_table2 <- url %>%
  read_html() %>%
  html_node(css = "#opinion-pell-table > div > div.g-item.g-sortable-table > table") %>%
  html_table()


```

## Create a visualization

Choose 3 variables and create a heuristic visualization using this dataset.